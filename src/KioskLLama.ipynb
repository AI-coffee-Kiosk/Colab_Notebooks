{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["# Clear Hugging Face model cache to avoid past errors\n","!rm -rf ~/.cache/huggingface"],"metadata":{"id":"4XmZuMr9F8X2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRxDDAV6rYK1"},"outputs":[],"source":["#Required Libraries\n","!pip install transformers\n","!pip install torch\n","!pip install huggingface_hub"]},{"cell_type":"code","source":["#Upgrade the libraries\n","!pip install --upgrade transformers\n","!pip install --upgrade torch"],"metadata":{"collapsed":true,"id":"QRShNB8C_yx2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prompt to enter your Hugging Face token securely\n","import os\n","os.environ[\"HF_TOKEN\"] = input(\"Enter your Hugging Face token: \")"],"metadata":{"id":"nzcjiw4Z_1MM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Logging into the Hugging face account\n","from huggingface_hub import login\n","login(token=os.getenv(\"HF_TOKEN\"), add_to_git_credential=True)"],"metadata":{"id":"_DZ7uAwj_1Aa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","# Variables to store order details\n","order = {\"type\": None, \"size\": None, \"extras\": None}\n","\n","def generate_response(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    outputs = model.generate(inputs.input_ids, max_length=100, do_sample=True, top_k=50, top_p=0.95)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","def coffee_order_chatbot():\n","    print(\"Bot: 안녕하세요! 커피 주문을 도와드리겠습니다. 어떤 종류의 커피를 원하시나요?\")\n","\n","    while True:\n","        user_input = input(\"You: \")\n","\n","        # Exit command\n","        if user_input.lower() in [\"exit\", \"quit\"]:\n","            print(\"Bot: 주문을 종료하였습니다. 감사합니다!\")\n","            break\n","\n","        # Determine the stage of ordering based on the user's input and current order status\n","        if order[\"type\"] is None:\n","            order[\"type\"] = user_input\n","            response = \"커피 사이즈를 선택해주세요: 작은 사이즈, 중간 사이즈, 또는 큰 사이즈.\"\n","\n","        elif order[\"size\"] is None:\n","            order[\"size\"] = user_input\n","            response = \"추가 옵션이 있으신가요? (예: 우유, 시럽 등)\"\n","\n","        elif order[\"extras\"] is None:\n","            order[\"extras\"] = user_input\n","            response = f\"확인합니다. 주문하신 커피는 {order['type']} ({order['size']}), 추가 옵션: {order['extras']}입니다. 맞나요?\"\n","\n","        else:\n","            # Confirm and finalize order\n","            if \"네\" in user_input or \"맞아요\" in user_input:\n","                response = \"주문이 완료되었습니다. 감사합니다!\"\n","                print(f\"Bot: {response}\")\n","                break\n","            else:\n","                response = \"죄송합니다. 다시 주문을 시작하겠습니다.\"\n","                order[\"type\"], order[\"size\"], order[\"extras\"] = None, None, None\n","\n","        print(f\"Bot: {response}\")\n","\n","# Run the chatbot\n","coffee_order_chatbot()\n"],"metadata":{"id":"G936s7XcdCTX"},"execution_count":null,"outputs":[]}]}