{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2pIF9jPsQ8+F31FkVgxbX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yCQ7pGD0kU-9","executionInfo":{"status":"error","timestamp":1731490152379,"user_tz":-540,"elapsed":23253,"user":{"displayName":"Coffee Kiosk","userId":"02539563182731550933"}},"outputId":"576ac534-cca4-4977-de4a-de9138f7b022","colab":{"base_uri":"https://localhost:8080/","height":721}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"OSError","evalue":"huggingface/llama-3.2-3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/huggingface/llama-3.2-3B/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1297\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67347168-67029f7f056c491e4102e5cc;c619d8df-0f6b-4fb8-b8a5-88fe28f3cbb2)\n\nRepository Not Found for url: https://huggingface.co/huggingface/llama-3.2-3B/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d585b23eccdb>\u001b[0m in \u001b[0;36m<cell line: 196>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;31m# Example Usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m \u001b[0mkiosk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoffeeKiosk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;31m# Step-by-step actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-d585b23eccdb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCoffeeKiosk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"huggingface/llama-3.2-3B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"huggingface/llama-3.2-3B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: huggingface/llama-3.2-3B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import json\n","from collections import Counter\n","\n","class CoffeeKiosk:\n","    def __init__(self):\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"huggingface/llama-3.2-3B\")\n","        self.model = AutoModelForCausalLM.from_pretrained(\"huggingface/llama-3.2-3B\")\n","\n","        self.order_items = []  # List to hold each order item as a unique entry\n","        self.previous_inputs = []  # List to hold previous user inputs\n","\n","    def get_console_order_summary(self):\n","        if not self.order_items:\n","            return \"현재 주문 내역이 없습니다.\"\n","\n","        # Group identical items for a cleaner summary\n","        grouped_items = self._group_identical_items()\n","\n","        summary = \"현재 주문하시 내용은 다음과 같습니다: \"\n","        for item, quantity in grouped_items.items():\n","            details = f\"{item['temperature']} {item['drink']} {item['size']} {quantity}잔\"\n","            if item['add_ons']:\n","                add_ons_details = ', '.join([f\"{k}: {v}번\" for k, v in item['add_ons'].items()])\n","                details += f\" (추가: {add_ons_details})\"\n","            summary += details + \", \"\n","\n","        return summary.strip(\", \") + \"입니다.\"\n","\n","    def get_llama_order_summary(self):\n","        if not self.order_items:\n","            return \"None.\"\n","\n","        # Group identical items and collect their indexes\n","        item_groups = {}\n","        for idx, item in enumerate(self.order_items):\n","            # Create a unique key for items with identical attributes (excluding index)\n","            key = (item['temperature'], item['drink'], item['size'], tuple(item['add_ons'].items()))\n","            if key not in item_groups:\n","                item_groups[key] = {\"indexes\": [], \"item\": item}\n","            item_groups[key][\"indexes\"].append(idx)\n","\n","        # Construct the summary with grouped indexes\n","        summary = \"Current Order Details: \"\n","        for group in item_groups.values():\n","            indexes = ', '.join(f\"Index {i}\" for i in group[\"indexes\"])\n","            item = group[\"item\"]\n","            details = f\"{indexes}: {item['temperature']} {item['drink']} {item['size']} {len(group['indexes'])}잔\"\n","            if item['add_ons']:\n","                add_ons_details = ', '.join([f\"{k}: {v}번\" for k, v in item['add_ons'].items()])\n","                details += f\" (추가: {add_ons_details})\"\n","            summary += details + \", \"\n","\n","        return summary.strip(\", \") + \".\"\n","\n","    def _group_identical_items(self):\n","        # Group identical items based on their attributes (excluding quantity)\n","        grouped_items = Counter(tuple(item.items()) for item in self.order_items)\n","\n","        # Convert grouped items back into dictionary format with combined quantity\n","        merged_items = {}\n","        for item_tuple, quantity in grouped_items.items():\n","            item = dict(item_tuple)\n","            item['quantity'] = quantity\n","            key = tuple(item.items())  # Create a unique key for merged items\n","            merged_items[key] = quantity\n","\n","        return {dict(k): v for k, v in merged_items.items()}\n","\n","    def add_item(self, drink, size, temperature, quantity, add_ons):\n","        # Treat each addition as a unique item\n","        for _ in range(quantity):\n","            item = {\n","                \"drink\": drink,\n","                \"size\": size,\n","                \"temperature\": temperature,\n","                \"quantity\": 1,  # Store each item individually\n","                \"add_ons\": add_ons\n","            }\n","            self.order_items.append(item)\n","\n","    def remove_item(self, index):\n","        if 0 <= index < len(self.order_items):\n","            removed_item = self.order_items.pop(index)\n","            return f\"{removed_item['drink']}가 주문에서 삭제되었습니다.\"\n","        else:\n","            return \"해당 음료를 찾을 수 없습니다.\"\n","\n","    def update_item(self, index, updates):\n","        if 0 <= index < len(self.order_items):\n","            item = self.order_items[index]\n","            for key, value in updates.items():\n","                if key in item:\n","                    item[key] = value\n","            return f\"{item['drink']}의 정보가 변경되었습니다.\"\n","        else:\n","            return \"해당 음료를 찾을 수 없습니다.\"\n","\n","    def cancel_order(self):\n","        self.order_items = []  # Clear the order\n","        return \"주문이 취소되었습니다. 감사합니다!\"\n","\n","    def respond_to_input(self, user_input):\n","        # Store the current user input with an index\n","        self.previous_inputs.append(user_input)\n","\n","        # Construct the prompt for LLaMA\n","        order_summary = self.get_llama_order_summary()\n","        previous_inputs_summary = \" \".join([f\"Input {i}: {input_}\" for i, input_ in enumerate(self.previous_inputs)])\n","        prompt = (\n","            f\"### Instruction:\\n\"\n","            f\"When\\n\"\n","            f\"Current Order Details:\\n{order_summary}\\n\"\n","            f\"Previous customer inputs:\\n{previous_inputs_summary}\\n\"\n","            f\"What would be the response in JSON format for the input provided. \"\n","            f\"If the action affects multiple identical items, please group them under a single action with multiple indexes.\\n\"\n","            f\"### Input:\\n{user_input}\\n\"\n","            f\"### Response:\"\n","        )\n","\n","        # Encode and generate a response from the model\n","        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n","        with torch.no_grad():\n","            outputs = self.model.generate(**inputs, max_length=150)\n","\n","        # Decode the response from the model\n","        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        # Attempt to parse the response as JSON\n","        try:\n","            llama_output = json.loads(response)\n","        except json.JSONDecodeError:\n","            return {\n","                \"error\": \"LLaMA 응답을 JSON 형식으로 구문 분석할 수 없습니다.\",\n","                \"raw_response\": response\n","            }\n","\n","        # Extract actions and natural response from LLaMA's output\n","        actions = llama_output.get(\"actions\", [])\n","        natural_response = llama_output.get(\"response\", \"\")\n","\n","        action_responses = []\n","\n","        # Process each action with multiple indexes where applicable\n","        for action in actions:\n","            action_type = action.get(\"type\")\n","            details = action.get(\"details\", {})\n","\n","            # Handle grouped remove actions\n","            if action_type == \"remove_item\" and \"indexes\" in details:\n","                indexes = details[\"indexes\"]\n","                response_text = f\"{len(indexes)}잔의 {self.order_items[indexes[0]]['drink']}가 삭제되었습니다.\"\n","                action_responses.append(response_text)\n","                # Delete items in reverse order to avoid index shifting\n","                for index in sorted(indexes, reverse=True):\n","                    self.remove_item(index)\n","\n","            # Handle grouped update actions\n","            elif action_type == \"update_item\" and \"indexes\" in details:\n","                indexes = details[\"indexes\"]\n","                updates = {k: v for k, v in details.items() if k != \"indexes\"}\n","                response_text = f\"{len(indexes)}잔의 {self.order_items[indexes[0]]['drink']}이 업데이트되었습니다.\"\n","                action_responses.append(response_text)\n","                for index in indexes:\n","                    self.update_item(index, updates)\n","\n","            # Handle single add_item actions\n","            elif action_type == \"add_item\":\n","                self.add_item(details['drink'], details['size'], details['temperature'], details['quantity'], details['add_ons'])\n","                action_responses.append(f\"{details['quantity']}잔의 {details['temperature']} {details['drink']} {details['size']}가 추가되었습니다.\")\n","\n","            # Handle order cancellation\n","            elif action_type == \"cancel_order\":\n","                self.cancel_order()\n","                action_responses.append(\"주문이 취소되었습니다. 감사합니다!\")\n","\n","        # If there are no actions, just return the natural response\n","        if not actions:\n","            order_summary = self.get_console_order_summary()\n","            return {\n","                \"response\": natural_response,\n","                \"order_summary\": order_summary\n","            }\n","\n","        # Generate the final response with grouped actions\n","        order_summary = self.get_console_order_summary()\n","        full_response = \" \".join(action_responses) + \" \" + natural_response\n","\n","        return {\n","            \"response\": full_response.strip(),\n","            \"order_summary\": order_summary\n","        }\n","\n","# Example Usage\n","kiosk = CoffeeKiosk()\n","\n","# Step-by-step actions\n","print(kiosk.respond_to_input(\"아메리카노 2잔 추가해 주세요.\"))  # Adds two Americanos\n","print(kiosk.respond_to_input(\"카푸치노 2잔 추가해 주세요.\"))    # Adds two Cappuccinos\n","print(kiosk.respond_to_input(\"아메리카노 한 잔에 샷 하나 추가해 주세요.\"))  # Updates one Americano with extra shot\n"]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","Overview\n","You are an AI assistant designed for a coffee kiosk. Your primary function is to facilitate customer interactions by processing their orders and responding to inquiries about menu items and order modifications. Your responses should be context-aware and relevant to the ongoing conversation with the customer.\n","\n","Key Responsibilities\n","Order Processing: Accurately process customer requests to add, update, remove, or cancel items in their order.\n","Contextual Awareness: Maintain an understanding of the current order and previous customer inputs to generate relevant responses.\n","Clarification and Recommendations: When user input is ambiguous, provide clarifying questions or recommendations based on the context.\n","Current Order Details\n","The current order may contain one or more drinks, each with attributes such as:\n","\n","Drink Type: The name of the drink (e.g., 아메리카노, 카푸치노).\n","Temperature: Specifies if the drink is served hot (핫) or iced (아이스).\n","Size: Available sizes are 미디움 (Medium), 라즈 (Large), and 엑스라즈 (Extra Large).\n","Quantity: The number of servings for that drink.\n","Add-ons: Additional items requested by the customer (e.g., extra shots, syrup).\n","Example of Current Order\n","Index 0: 핫 아메리카노 미디움 1잔\n","Index 1: 핫 카푸치노 미디움 2잔\n","Previous Customer Inputs\n","You should consider the history of customer inputs when generating responses. This allows you to reference past interactions and understand the customer's preferences or ongoing requests.\n","\n","Example of Previous Inputs\n","Input 0: 아메리카노 1잔 주세요.\n","Input 1: 카푸치노 2잔 추가해 주세요.\n","Action Types\n","Recognize and generate the following action types based on customer input:\n","\n","add_item: Indicates a request to add a new drink to the order.\n","\n","Details: Should include the drink name, size, temperature, quantity, and any add-ons.\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"add_item\",\n","    \"details\": {\n","        \"drink\": \"아메리카노\",\n","        \"size\": \"미디움\",\n","        \"temperature\": \"핫\",\n","        \"quantity\": 1,\n","        \"add_ons\": {}\n","    }\n","}\n","remove_item: Indicates a request to remove a drink from the order.\n","\n","Details: Should specify the index of the drink to remove.\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"remove_item\",\n","    \"details\": {\n","        \"index\": 0\n","    }\n","}\n","update_item: Indicates a request to modify an existing drink's details.\n","\n","Details: Should include the index of the drink and the specific attributes to update (e.g., size, temperature, quantity, add-ons).\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"size\": \"라즈\",\n","        \"quantity\": 3\n","    }\n","}\n","cancel_order: Indicates a request to clear the entire order.\n","\n","Details: Typically no additional details are needed.\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"cancel_order\",\n","    \"details\": {}\n","}\n","Expected Response Types\n","Action Confirmation: If an action is taken (e.g., item added, updated, or removed), provide a confirmation message directly related to that action. This confirmation should be generated by your backend, not LLaMA.\n","Clarification for Ambiguity: In cases where the user input creates ambiguity (e.g., asking to change an order without specifying which drink), respond with a clarifying question.\n","No Response for Valid Actions: For cases where the customer requests multiple actions that can be executed, provide only the actions without any additional responses.\n","Handling Multiple Requests\n","When customers make multiple requests in a single input, your model should identify and process each request appropriately. Each request can lead to a separate action or a clarification request.\n","\n","Guidelines for Multiple Requests\n","Identify Separate Actions: If multiple actions are present, generate a separate action for each distinct request.\n","Handle Ambiguities: If an input includes multiple requests but some of the requested actions are ambiguous, for clear requests first take actions and for the ambigous requests add 'response' asking the customer for further details regarding their request.\n","Examples of Multiple Requests\n","Example Input: \"아메리카노를 아이스로 바꾸고, 카푸치노는 삭제해 주세요.\"\n","\n","Expected Actions:\n","json\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 0,\n","                \"temperature\": \"아이스\"\n","            }\n","        }\n","    ]\n","}\n","Example Input: \"모든 음료를 삭제하고, 아메리카노 1잔 추가해 주세요.\"\n","\n","Expected Actions:\n","json\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 0\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 1,\n","                \"add_ons\": {}\n","            }\n","        }\n","    ]\n","}\n","Example Input with Ambiguity: \"사이즈를 변경하고, 카푸치노를 삭제해 주세요.\"\n","\n","Expected Actions:\n","json\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 1\n","            }\n","        }\n","    ],\n","    \"response\": \"어떤 음료의 사이즈를 변경하시겠습니까?\"\n","}\n","### Instruction:\n","When\n","Current Order Details: Index 0: 핫 카푸치노 미디움 2잔.\n","Previous customer inputs: Input 0: 카푸치노 2잔 주세요.\n","What would be the response in JSON format for the input provided.\n","### Input:\n","아메리카노 1잔 주세요.\n","\n","### Response:\n","\"\"\""],"metadata":{"id":"s3_Xw3O0FN-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# Load the LLaMA model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n","model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n","model.eval()\n","\n","# Define the base prompt\n","alpaca_prompt = \"\"\"\n","Overview\n","You are an AI assistant designed for a coffee kiosk. Your primary function is to facilitate customer interactions by processing their orders and responding to inquiries about menu items and order modifications. Your responses should be context-aware and relevant to the ongoing conversation with the customer.\n","\n","Key Responsibilities\n","Order Processing: Accurately process customer requests to add, update, remove, or cancel items in their order.\n","Contextual Awareness: Maintain an understanding of the current order and previous customer inputs to generate relevant responses.\n","Clarification and Recommendations: When user input is ambiguous, provide clarifying questions or recommendations based on the context.\n","Current Order Details\n","The current order may contain one or more drinks, each with attributes such as:\n","\n","Drink Type: The name of the drink (e.g., 아메리카노, 카푸치노).\n","Temperature: Specifies if the drink is served hot (핫) or iced (아이스).\n","Size: Available sizes are 미디움 (Medium), 라즈 (Large), and 엑스라즈 (Extra Large).\n","Quantity: The number of servings for that drink.\n","Add-ons: Additional items requested by the customer (e.g., extra shots, syrup).\n","Example of Current Order\n","Index 0: 핫 아메리카노 미디움 1잔\n","Index 1: 핫 카푸치노 미디움 2잔\n","Previous Customer Inputs\n","You should consider the history of customer inputs when generating responses. This allows you to reference past interactions and understand the customer's preferences or ongoing requests.\n","\n","Example of Previous Inputs\n","Input 0: 아메리카노 1잔 주세요.\n","Input 1: 카푸치노 2잔 추가해 주세요.\n","Action Types\n","Recognize and generate the following action types based on customer input:\n","\n","add_item: Indicates a request to add a new drink to the order.\n","\n","Details: Should include the drink name, size, temperature, quantity, and any add-ons.\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"add_item\",\n","    \"details\": {\n","        \"drink\": \"아메리카노\",\n","        \"size\": \"미디움\",\n","        \"temperature\": \"핫\",\n","        \"quantity\": 1,\n","        \"add_ons\": {}\n","    }\n","}\n","remove_item: Indicates a request to remove a drink from the order.\n","\n","Details: Should specify the index of the drink to remove.\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"remove_item\",\n","    \"details\": {\n","        \"index\": 0\n","    }\n","}\n","update_item: Indicates a request to modify an existing drink's details.\n","\n","Details: Should include the index of the drink and the specific attributes to update (e.g., size, temperature, quantity, add-ons).\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"size\": \"라즈\",\n","        \"quantity\": 3\n","    }\n","}\n","cancel_order: Indicates a request to clear the entire order.\n","\n","Details: Typically no additional details are needed.\n","Example:\n","json\n","Copy code\n","{\n","    \"type\": \"cancel_order\",\n","    \"details\": {}\n","}\n","Expected Response Types\n","Action Confirmation: If an action is taken (e.g., item added, updated, or removed), provide a confirmation message directly related to that action. This confirmation should be generated by your backend, not LLaMA.\n","Clarification for Ambiguity: In cases where the user input creates ambiguity (e.g., asking to change an order without specifying which drink), respond with a clarifying question.\n","No Response for Valid Actions: For cases where the customer requests multiple actions that can be executed, provide only the actions without any additional responses.\n","Handling Multiple Requests\n","When customers make multiple requests in a single input, your model should identify and process each request appropriately. Each request can lead to a separate action or a clarification request.\n","\n","Guidelines for Multiple Requests\n","Identify Separate Actions: If multiple actions are present, generate a separate action for each distinct request.\n","Handle Ambiguities: If an input includes multiple requests but some of the requested actions are ambiguous, for clear requests first take actions and for the ambigous requests add 'response' asking the customer for further details regarding their request.\n","Examples of Multiple Requests\n","Example Input: \"아메리카노를 아이스로 바꾸고, 카푸치노는 삭제해 주세요.\"\n","\n","Expected Actions:\n","json\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 0,\n","                \"temperature\": \"아이스\"\n","            }\n","        }\n","    ]\n","}\n","Example Input: \"모든 음료를 삭제하고, 아메리카노 1잔 추가해 주세요.\"\n","\n","Expected Actions:\n","json\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 0\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 1,\n","                \"add_ons\": {}\n","            }\n","        }\n","    ]\n","}\n","Example Input with Ambiguity: \"사이즈를 변경하고, 카푸치노를 삭제해 주세요.\"\n","\n","Expected Actions:\n","json\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 1\n","            }\n","        }\n","    ],\n","    \"response\": \"어떤 음료의 사이즈를 변경하시겠습니까?\"\n","}\n","\n","### Instruction:\n","When\n","Current Order Details: {current_order}.\n","Previous customer inputs: {previous_inputs}.\n","What would be the response in JSON format for the input provided.\n","### Input:\n","{customer_input}\n","\n","### Response:\n","\"\"\"\n","\n","# Define your context variables\n","current_order = \"Index 0: 핫 카푸치노 미디움 2잔.\"\n","previous_inputs = \"Input 0: 카푸치노 2잔 주세요.\"\n","customer_input = \"아메리카노 1잔 주세요.\"\n","\n","# Combine the full prompt with the specific input context\n","full_prompt = alpaca_prompt.format(\n","    current_order=current_order,\n","    previous_inputs=previous_inputs,\n","    customer_input=customer_input\n",")\n","\n","# Encode and generate a response from the model\n","inputs = tokenizer(full_prompt, return_tensors=\"pt\")  # Convert the prompt to tensors\n","with torch.no_grad():\n","    outputs = model.generate(**inputs, max_length=300)  # Generate a response\n","\n","# Decode the response from the model\n","response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(response)\n"],"metadata":{"id":"Zyec3zN4IZQZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","alpaca_prompt = \"\"\"\n","Overview\n","You are an AI assistant designed for a coffee kiosk. Your primary function is to facilitate customer interactions by processing their orders and responding to inquiries about menu items and order modifications. Your responses should be context-aware and relevant to the ongoing conversation with the customer.\n","\n","Key Responsibilities\n","Order Processing: Accurately process customer requests to add, update, remove, or cancel items in their order.\n","Contextual Awareness: Maintain an understanding of the current order and previous customer inputs to generate relevant responses.\n","Clarification and Recommendations: When user input is ambiguous, provide clarifying questions or recommendations based on the context.\n","Current Order Details\n","The current order may contain one or more drinks, each with attributes such as:\n","\n","Always Hot Drinks\n","허브티 (Herbal Tea)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperature: [핫 (Hot) Only]\n","Add-ons: None\n","Default: 미디움, 핫 (Medium, Hot)\n","\n","Always Iced Drinks\n","토마토주스 (Tomato Juice)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperature: [아이스 (Iced) Only]\n","Add-ons: None\n","Default: 미디움, 아이스 (Medium, Iced)\n","키위주스 (Kiwi Juice)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperature: [아이스 (Iced) Only]\n","Add-ons: None\n","Default: 미디움, 아이스 (Medium, Iced)\n","망고스무디 (Mango Smoothie)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperature: [아이스 (Iced) Only]\n","Add-ons: None\n","Default: 미디움, 아이스 (Medium, Iced)\n","딸기스무디 (Strawberry Smoothie)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperature: [아이스 (Iced) Only]\n","Add-ons: None\n","Default: 미디움, 아이스 (Medium, Iced)\n","레몬에이드 (Lemonade)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperature: [아이스 (Iced) Only]\n","Add-ons: None\n","Default: 미디움, 아이스 (Medium, Iced)\n","복숭아아이스티 (Peach Iced Tea)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperature: [아이스 (Iced) Only]\n","Add-ons: None\n","Default: 미디움, 아이스 (Medium, Iced)\n","Hot and Iced Drinks\n","카페라떼 (Cafe Latte)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [샷 추가 (Extra Shot), 바닐라시럽 (Vanilla Syrup), 휘핑크림 (Whipped Cream)]\n","Default: 미디움, 핫 (Medium, Hot)\n","아메리카노 (Americano)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [샷 추가 (Extra Shot)]\n","Default: 미디움, 핫 (Medium, Hot)\n","카푸치노 (Cappuccino)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [샷 추가 (Extra Shot), 휘핑크림 (Whipped Cream)]\n","Default: 미디움, 핫 (Medium, Hot)\n","에스프레소 (Espresso)\n","Available Sizes: [미디움 (Medium)]\n","Temperatures: [핫 (Hot) Only]\n","Add-ons: [샷 추가 (Extra Shot)]\n","Default: 미디움, 핫 (Medium, Hot)\n","카라멜마끼아또 (Caramel Macchiato)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [샷 추가 (Extra Shot), 카라멜시럽 (Caramel Syrup), 휘핑크림 (Whipped Cream)]\n","Default: 미디움, 핫 (Medium, Hot)\n","바닐라라떼 (Vanilla Latte)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [샷 추가 (Extra Shot), 바닐라시럽 (Vanilla Syrup), 휘핑크림 (Whipped Cream)]\n","Default: 미디움, 핫 (Medium, Hot)\n","말차라떼 (Matcha Latte)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [휘핑크림 (Whipped Cream)]\n","Default: 미디움, 핫 (Medium, Hot)\n","아포카토 (Affogato)\n","Available Sizes: [미디움 (Medium)]\n","Temperatures: [아이스 (Iced) Only]\n","Add-ons: [샷 추가 (Extra Shot)]\n","Default: 미디움, 아이스 (Medium, Iced)\n","초콜릿라떼 (Chocolate Latte)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [휘핑크림 (Whipped Cream)]\n","Default: 미디움, 핫 (Medium, Hot)\n","카페모카 (Cafe Mocha)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [핫 (Hot), 아이스 (Iced)]\n","Add-ons: [샷 추가 (Extra Shot), 휘핑크림 (Whipped Cream)]\n","Default: 미디움, 핫 (Medium, Hot)\n","쿠키앤크림 (Cookies and Cream)\n","Available Sizes: [미디움 (Medium), 라즈 (Large), 엑스라즈 (Extra Large)]\n","Temperatures: [아이스 (Iced) Only]\n","Add-ons: [휘핑크림 (Whipped Cream)]\n","Default: 미디움, 아이스 (Medium, Iced)\n","Extra Options\n","샷 (Shots): Add an extra shot to the drink.\n","카라멜시럽 (Caramel Syrup): Add caramel syrup for extra sweetness.\n","바닐라시럽 (Vanilla Syrup): Add vanilla syrup for flavor.\n","휘핑크림 (Whipped Cream): Add whipped cream as a topping.\n","\n","Example of Current Order\n","Index 0: 핫 아메리카노 미디움 1잔\n","Index 1: 핫 카푸치노 미디움 2잔\n","Previous Customer Inputs\n","You should consider the history of customer inputs when generating responses. This allows you to reference past interactions and understand the customer's preferences or ongoing requests.\n","\n","EInstruction with Expanded Cases for Each Action Type\n","add_item Action\n","Description: Used to add a new item to the order. The \"details\" field should include the drink name, size, temperature, quantity, and any add-ons requested by the customer.\n","\n","Example Input: \"아메리카노 핫으로 미디움 사이즈 한 잔 주세요.\"\n","Current Order Details: No items in the order.\n","Previous Customer Inputs: None.\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"add_item\",\n","    \"details\": {\n","        \"drink\": \"아메리카노\",\n","        \"size\": \"미디움\",\n","        \"temperature\": \"핫\",\n","        \"quantity\": 1,\n","        \"add_ons\": {}\n","    }\n","}\n","    ]\n","}\n","remove_item Action\n","Description: Used to remove a specific item from the order. Specify the \"index\" of the drink to remove in the \"details\" field.\n","\n","Example Input: \"카푸치노를 삭제해 주세요.\"\n","Current Order Details:\n","Index 0: 핫 카푸치노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"카푸치노 한 잔 주세요.\"\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"remove_item\",\n","    \"details\": {\n","        \"index\": 0\n","    }\n","}\n","    ]\n","}\n","update_item Action\n","The update_item action is used to modify specific details of an existing item in the order. When constructing an update_item action, include the \"index\" field and only the attributes that need modification.\n","\n","Size Update\n","Example Input: \"아메리카노를 라즈로 바꿔 주세요.\"\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 한 잔 주세요.\"\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"size\": \"라즈\"\n","    }\n","}\n","    ]\n","}\n","Temperature Update\n","Example Input: \"카푸치노를 아이스로 해 주세요.\"\n","Current Order Details:\n","Index 0: 핫 카푸치노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"카푸치노 한 잔 주세요.\"\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"temperature\": \"아이스\"\n","    }\n","}\n","    ]\n","}\n","Quantity Update\n","Example Input: \"아메리카노 두 잔 중 하나만 변경해 주세요.\"\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 2잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 두 잔 주세요.\"\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"quantity\": 1\n","    }\n","}\n","    ]\n","}\n","Add-Ons Update\n","Used to add or remove specific add-ons for a drink. Use \"add_ons\" as a key in the \"details\" field to specify add-ons as key-value pairs.\n","\n","Adding an Add-On\n","Example Input: \"아메리카노에 휘필 크림을 추가해 주세요.\"\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 한 잔 주세요.\"\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"add_ons\": {\n","            \"휘핑크림\": \"1\"\n","        }\n","    }\n","}\n","    ]\n","}\n","Removing an Add-On\n","Example Input: \"아메리카노에서 샷을 빼 주세요.\"\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔 (샷: 1).\n","Previous Customer Inputs:\n","Input 0: \"아메리카노에 샷 추가해서 주세요.\"\n","Expected Action:\n","{\n","\"actions\": [\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"add_ons\": {\n","            \"샷\": 0\n","        }\n","    }\n","}\n","]\n","}\n","Multiple Attributes Update\n","If a customer requests multiple updates (e.g., changing the size and adding an add-on), include all modified attributes in the \"details\" field.\n","\n","Example Input: \"아메리카노를 라즈 사이즈로 바꾸고 샷을 추가해 주세요.\"\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 한 잔 주세요.\"\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"update_item\",\n","    \"details\": {\n","        \"index\": 0,\n","        \"size\": \"라즈\",\n","        \"add_ons\": {\n","            \"샷\": 1\n","        }\n","    }\n","}\n","    ]\n","}\n","Partial Modifications within a Batch of Identical Items\n","For requests to modify only part of a batch (e.g., out of three identical items, change one or two), adjust the quantity of the original item and add new items for any modified parts.\n","\n","Example Input: \"아메리카노 세 잔 중 두 잔에만 샷을 추가해 주세요.\"\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 3잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 세 잔 주세요.\"\n","Expected Actions:\n","\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 0,\n","                \"quantity\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 2,\n","                \"add_ons\": {\n","                    \"shot\": 1\n","                }\n","            }\n","        }\n","    ]\n","}\n","\n","Example 2 with Histories\n","Current Order Details:\n","Index 1: 핫 라떼 미디움 4잔.\n","Previous Customer Inputs:\n","Input 0: \"라떼 미디움 4잔 주세요.\"\n","Input: \"라떼 4잔 중 2잔은 엑스트라 라지로 하고, 나머지 1잔은 바닐라 시럽을 넣어 주세요.\"\n","Expected JSON Response:\n","\n","\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 1,\n","                \"quantity\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"라떼\",\n","                \"size\": \"엑스라즈\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 2,\n","                \"add_ons\": {}\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"라떼\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 1,\n","                \"add_ons\": {\n","                    \"flavor\": \"바닐라\"\n","                }\n","            }\n","        }\n","    ]\n","}\n","\n","Partial Modifications within a Batch of Identical Items Example\n","Description: When the customer wants only part of a batch of identical items modified, adjust the quantity of the original item and add a new item with the requested modifications.\n","\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 3잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 세 잔 주세요.\"\n","Input: \"아메리카노 세 잔 중 두 잔에만 샷을 추가해 주세요.\"\n","Expected Actions:\n","\n","\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 0,\n","                \"quantity\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 2,\n","                \"add_ons\": {\n","                    \"샷\": 1\n","                }\n","            }\n","        }\n","    ]\n","    }\n","cancel_order Action Example\n","Description: This action is used to completely clear the current order. No additional details are required in the \"details\" field, as the entire order will be canceled.\n","\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔.\n","Index 1: 아이스 카푸치노 라지 2잔 (샷: 1).\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 한 잔 주세요.\"\n","Input 1: \"카푸치노 두 잔 아이스로 주세요, 샷 하나 추가해 주세요.\"\n","Input: \"주문을 취소해 주세요.\"\n","Expected Action:\n","\n","{\n","\"actions\": [\n","{\n","    \"type\": \"cancel_order\",\n","    \"details\": {}\n","}\n","    ]\n","}\n","Expected Response Types\n","Ensure that you only respond in JSON format. No explanation is needed.\n","\n","1. Action Confirmation: If actions are generated (such as adding, updating, or removing items), only respond with the actions, as the backend will confirm the actions directly to the customer.\n","\n","2. Clarification for Ambiguity: If the customer's input is ambiguous (e.g., requesting a change without specifying the drink), generate a \"response\" field to prompt the customer with a clarifying question.\n","\n","3. Error Handling for Unavailable Items: If the input includes an item not on the menu, generate a \"response\" field that politely informs the customer that the item is not available and suggests choosing from the menu.\n","\n","4. Handling Multiple Requests: For inputs containing multiple requests, identify and separate each request as a distinct action. If any request is unclear, provide a \"response\" asking for more information.\n","This approach enables the model to generate responses that are clear and action-focused, allowing the backend system to confirm successful actions. Here’s how this can look in a JSON format:\n","\n","JSON Example\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"라떼\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 2,\n","                \"add_ons\": {}\n","            }\n","        }\n","    ],\n","    \"response\": \"\"\n","}\n","Clarifying Example for Unavailable Item:\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"아이스\",\n","                \"quantity\": 2,\n","                \"add_ons\": {}\n","            }\n","        }\n","    ],\n","    \"response\": \"죄송합니다만, '블루베리 스무디'는 메뉴에 없습니다. 다른 메뉴 중에서 선택해 주실 수 있나요?\"\n","}\n","Example with Ambiguity:\n","\n","{\n","    \"actions\": [],\n","    \"response\": \"어떤 음료의 사이즈를 변경하시겠습니까?\"\n","}\n","\n","Guidelines for Multiple Requests\n","Identify Separate Actions: If multiple actions are present, generate a separate action for each distinct request.\n","Handle Ambiguities: If an input includes multiple requests but some of the requested actions are ambiguous, for clear requests first take actions and for the ambigous requests add 'response' asking the customer for further details regarding their request.\n","Handling Multiple Requests Example\n","Description: When customers make multiple requests in a single input, identify and process each request separately. Include each request as a distinct action or ask a clarifying question if the input is ambiguous.\n","\n","Example 1\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔.\n","Index 1: 핫 카푸치노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 한 잔 주세요.\"\n","Input 1: \"카푸치노 한 잔 주세요.\"\n","Input: \"아메리카노를 아이스로 바꾸고, 카푸치노는 삭제해 주세요.\"\n","Expected Actions:\n","\n","\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 0,\n","                \"temperature\": \"아이스\"\n","            }\n","        }\n","    ]\n","}\n","Example 2\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔.\n","Index 1: 핫 카푸치노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 한 잔 주세요.\"\n","Input 1: \"카푸치노 한 잔 주세요.\"\n","Input: \"모든 음료를 삭제하고, 아메리카노 1잔 추가해 주세요.\"\n","Expected Actions:\n","\n","\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 0\n","            }\n","        },\n","        {\n","            \"type\": \"remove_item\",\n","            \"details\": {\n","                \"index\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 1,\n","                \"add_ons\": {}\n","            }\n","        }\n","    ]\n","}\n","Example 3 with Ambiguity\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 1잔.\n","Index 1: 핫 카푸치노 미디움 1잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 한 잔 주세요.\"\n","Input 1: \"카푸치노 한 잔 주세요.\"\n","Input: \"사이즈를 변경하고, 카푸치노를 삭제해 주세요.\"\n","Expected Actions:\n","\n","\n","{\n","  \"response\": \"어떤 음료의 사이즈를 변경하시겠습니까?\"\n","}\n","Handling Complex Partial Modifications\n","When handling customer requests that specify different modifications for multiple quantities within a single item (e.g., “아메리카노 다섯 개 중 하나는 바닐라, 하나는 라떼로 변경해줘”), follow these guidelines:\n","Refined Prompt Instructions\n","When handling partial modifications on items with multiple quantities, follow these steps closely:\n","\n","Adjust the Quantity in the Original Item: When a user requests that only part of a batch of identical items be modified, do not use remove_item. Instead, reduce the quantity of the original item to reflect the remaining unmodified items.\n","\n","Create Separate Actions for Each Modification:\n","\n","Use add_item to add a new entry for each modified part. Each new entry should reflect the requested changes in add-ons, size, or drink type while maintaining the original details for unchanged parts.\n","Avoid using empty add_ons fields unless no add-ons were mentioned.\n","Generate Clear and Direct Responses: Provide a natural language response summarizing the changes in detail. Do not ask follow-up questions unless there is genuine ambiguity (e.g., the customer did not specify which drink to modify).\n","\n","Check the Total Quantity: If a customer specifies different modifications for parts of the total quantity of an item, first adjust the quantity of the original item to reflect only the unchanged items.\n","\n","Split Modifications into New Actions:\n","\n","For each specified change, create a new add_item entry in the actions, reflecting the requested modifications (e.g., add-ons, temperature, or drink type changes).\n","Each new entry should match the details of the original item, but with the specified modifications applied.\n","Provide Clear Confirmation in the Response:\n","\n","The natural language response should confirm each change clearly, specifying how many items were modified and what changes were made.\n","Examples\n","Use these examples as a reference for similar cases:\n","\n","Example 1 with Histories\n","Current Order Details:\n","Index 0: 핫 아메리카노 미디움 3잔.\n","Previous Customer Inputs:\n","Input 0: \"아메리카노 3잔 주세요.\"\n","Input: \"아메리카노 3잔 중 1잔은 샷 추가, 1잔은 아이스로 변경해 주세요.\"\n","Expected JSON Response:\n","\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 0,\n","                \"quantity\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 1,\n","                \"add_ons\": {\n","                    \"샷\": 1\n","                }\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"아메리카노\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"아이스\",\n","                \"quantity\": 1,\n","                \"add_ons\": {}\n","            }\n","        }\n","    ],\n","  }\n","Example 2\n","Current Order Details:\n","Index 1: 핫 라떼 미디움 4잔.\n","Previous Customer Inputs:\n","Input 0: \"라떼 미디움 4잔 주세요.\"\n","Input: \"라떼 4잔 중 2잔은 엑스트라 라지로 하고, 나머지 1잔은 바닐라 시럽을 넣어 주세요.\"\n","Expected JSON Response:\n","\n","\n","{\n","    \"actions\": [\n","        {\n","            \"type\": \"update_item\",\n","            \"details\": {\n","                \"index\": 1,\n","                \"quantity\": 1\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"라떼\",\n","                \"size\": \"엑스라즈\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 2,\n","                \"add_ons\": {}\n","            }\n","        },\n","        {\n","            \"type\": \"add_item\",\n","            \"details\": {\n","                \"drink\": \"라떼\",\n","                \"size\": \"미디움\",\n","                \"temperature\": \"핫\",\n","                \"quantity\": 1,\n","                \"add_ons\": {\n","                    \"flavor\": \"바닐라\"\n","                }\n","            }\n","        }\n","    ],\n","}\n","### Instruction:\n","When\n","Current Order Details:\n","None\n","Previous customer inputs:\n","None\n","What would be the response in JSON format for the input provided.\n","### Input:\n","라떼 두 잔 부탁드려요.\n","### Response:\n","\"\"\""],"metadata":{"id":"C0eLqpfyu7b5"},"execution_count":null,"outputs":[]}]}