{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers accelerate bitsandbytes\n"
      ],
      "metadata": {
        "id": "L5osv_EMQQDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n"
      ],
      "metadata": {
        "id": "S8B_2ziuQPaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Use your Hugging Face token here\n",
        "login(\"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\", add_to_git_credential=True)\n"
      ],
      "metadata": {
        "id": "Kkz_qiVTQb6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/llama-3.2-1b-instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/llama-3.2-1b-instruct\",\n",
        "    device_map=\"auto\",  # Automatically place the model on GPU\n",
        "    load_in_8bit=True    # Load in 8-bit to save memory (optional but helpful)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03guRAzHOPaU",
        "outputId": "14f65eec-4e45-4e9a-968f-eea3d5b90a6d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt\n",
        "prompt = \"Explain the impact of artificial intelligence on modern society.\"\n",
        "\n",
        "# Tokenize the input prompt\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate text\n",
        "outputs = model.generate(inputs.input_ids, max_length=100)\n",
        "\n",
        "# Decode and print the output\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddgyvqt6Og5L",
        "outputId": "41a17955-a9a4-47aa-9a53-da225f6f1744"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain the impact of artificial intelligence on modern society. The impact of artificial intelligence (AI) on modern society is multifaceted and far-reaching. AI has the potential to revolutionize various aspects of our lives, but it also raises several concerns that need to be addressed. Here are some of the key impacts of AI on modern society:\n",
            "\n",
            "1. **Job displacement**: AI has the potential to automate many jobs, leading to job displacement and unemployment. According to a report by the McKinsey Global\n"
          ]
        }
      ]
    }
  ]
}